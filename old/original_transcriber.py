import pyaudio
import numpy as np
import threading
import time
from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline
import torch

# ==================== AYARLAR ====================
SILENCE_THRESHOLD = 500      # Sessizlik eÅŸiÄŸi (dÃ¼ÅŸÃ¼k = hassas)
SILENCE_DURATION = 1.5       # KaÃ§ saniye sessizlik sonrasÄ± iÅŸle
SAMPLE_RATE = 16000          # Whisper iÃ§in 16kHz
CHUNK_SIZE = 1024            # Ses buffer boyutu

# ==================== WHISPER MODEL YÃœKLEME ====================
device = "cuda:0" if torch.cuda.is_available() else "cpu"
torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32

model_id = "openai/whisper-large-v3-turbo"

# Model cache'den yÃ¼klenecek (otomatik)
model = AutoModelForSpeechSeq2Seq.from_pretrained(
    model_id, 
    low_cpu_mem_usage=True
)
model.to(device)

processor = AutoProcessor.from_pretrained(model_id)

pipe = pipeline(
    "automatic-speech-recognition",
    model=model,
    tokenizer=processor.tokenizer,
    feature_extractor=processor.feature_extractor,
    torch_dtype=torch_dtype,
    device=device,
)

print(f"âœ… Model yÃ¼klendi ({device} Ã¼zerinde)")
print("=" * 60)

# ==================== SES KAYIT DEÄÄ°ÅKENLERÄ° ====================
audio_data = []
is_recording = False
last_sound_time = time.time()
lock = threading.Lock()

# ==================== PYAUDIO BAÅLAT ====================
p = pyaudio.PyAudio()

# Mevcut mikrofon listesini gÃ¶ster
print("\nğŸ¤ Mikrofon CihazlarÄ±:")
for i in range(p.get_device_count()):
    info = p.get_device_info_by_index(i)
    if info['maxInputChannels'] > 0:
        print(f"  [{i}] {info['name']}")
print("=" * 60)

# ==================== SES SEVÄ°YESÄ° HESAPLAMA ====================
def calculate_volume(audio_chunk):
    """Ses seviyesini hesapla (RMS - Root Mean Square)"""
    audio_array = np.frombuffer(audio_chunk, dtype=np.int16)
    rms = np.sqrt(np.mean(audio_array**2))
    return rms

# ==================== WHISPER Ä°LE TRANSKRÄ°PSÄ°YON ====================
def transcribe_audio(audio_frames):
    """Kaydedilen sesi Whisper ile metne Ã§evir"""
    if not audio_frames:
        return
    
    print("\nğŸ™ï¸  Ses iÅŸleniyor...")
    
    # Ses verilerini birleÅŸtir
    audio_bytes = b''.join(audio_frames)
    audio_array = np.frombuffer(audio_bytes, dtype=np.int16).astype(np.float32) / 32768.0
    
    # Whisper ile transkripsiyon
    try:
        result = pipe(
            {"sampling_rate": SAMPLE_RATE, "raw": audio_array},
            generate_kwargs={
                "language": "turkish",  # TÃ¼rkÃ§e iÃ§in
                "task": "transcribe"
            }
        )
        text = result["text"].strip()
        
        if text:
            print(f"ğŸ“ Metin: {text}")
            print("=" * 60)
        else:
            print("âš ï¸  Metin algÄ±lanamadÄ±")
    except Exception as e:
        print(f"âŒ Hata: {e}")

# ==================== SES CALLBACK FONKSÄ°YONU ====================
def audio_callback(in_data, frame_count, time_info, status):
    """PyAudio callback - mikrofon verisi geldiÄŸinde Ã§alÄ±ÅŸÄ±r"""
    global audio_data, is_recording, last_sound_time
    
    volume = calculate_volume(in_data)
    
    with lock:
        # Ses var mÄ±?
        if volume > SILENCE_THRESHOLD:
            if not is_recording:
                print("\nğŸ¤ KonuÅŸma baÅŸladÄ±...")
                is_recording = True
                audio_data = []
            
            audio_data.append(in_data)
            last_sound_time = time.time()
            
            # Ses seviyesi gÃ¶stergesi
            bar_length = int(volume / 100)
            print(f"\rğŸ”Š Ses: {'â–ˆ' * min(bar_length, 50)}", end="", flush=True)
        
        # Sessizlik var ve kayÄ±t yapÄ±lÄ±yorsa
        elif is_recording:
            silence_time = time.time() - last_sound_time
            
            if silence_time >= SILENCE_DURATION:
                print("\n\nâ¸ï¸  Sessizlik algÄ±landÄ±, iÅŸleniyor...")
                is_recording = False
                
                # Ses verilerini kopyala ve iÅŸle
                frames_to_process = audio_data.copy()
                audio_data = []
                
                # AyrÄ± thread'de iÅŸle (bloklamadan devam etsin)
                threading.Thread(
                    target=transcribe_audio, 
                    args=(frames_to_process,),
                    daemon=True
                ).start()
    
    return (in_data, pyaudio.paContinue)

# ==================== MÄ°KROFON AKIÅI BAÅLAT ====================
print("ğŸ™ï¸  Mikrofon dinleniyor... (Ã‡Ä±kmak iÃ§in Ctrl+C)")
print("ğŸ’¡ KonuÅŸun ve susun, sistem otomatik olarak metne Ã§evirecek")
print("=" * 60)

stream = p.open(
    format=pyaudio.paInt16,
    channels=1,
    rate=SAMPLE_RATE,
    input=True,
    frames_per_buffer=CHUNK_SIZE,
    stream_callback=audio_callback
)

stream.start_stream()

# ==================== Ã‡ALIÅMAYA DEVAM ET ====================
try:
    while stream.is_active():
        time.sleep(0.1)
except KeyboardInterrupt:
    print("\n\nğŸ‘‹ Program sonlandÄ±rÄ±lÄ±yor...")

# ==================== TEMÄ°ZLÄ°K ====================
stream.stop_stream()
stream.close()
p.terminate()
print("âœ… Temizlik tamamlandÄ±, gÃ¼le gÃ¼le!")